"""
SSE Ïä§Ìä∏Î¶¨Î∞ç ÏóîÎìúÌè¨Ïù∏Ìä∏

ChatGPTÏ≤òÎüº ÏßÑÌñâ ÏÉÅÌô©ÏùÑ Ïã§ÏãúÍ∞ÑÏúºÎ°ú ÏõπÏóê ÌëúÏãú
"""

from fastapi import APIRouter, Request
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Dict, Any, Optional, AsyncGenerator
import json
import asyncio
from datetime import datetime

from app.services.openai_service import OpenAIService

router = APIRouter()


class TravelPlanStreamRequest(BaseModel):
    """Ïä§Ìä∏Î¶¨Î∞ç Ïó¨Ìñâ Í≥ÑÌöç ÏöîÏ≤≠"""
    prompt: str
    preferences: Optional[Dict[str, Any]] = None


async def progress_generator(request: TravelPlanStreamRequest) -> AsyncGenerator[str, None]:
    """
    ÏßÑÌñâ ÏÉÅÌô©ÏùÑ SSE ÌòïÏãùÏúºÎ°ú Ïã§ÏãúÍ∞Ñ Ïä§Ìä∏Î¶¨Î∞ç
    ÌÅ¨Î°§ÎßÅÎêòÎäî Ïû•ÏÜåÎ•º ÌïòÎÇòÏî© ÌëúÏãú
    """
    
    try:
        # 1. ÏãúÏûë
        yield f"data: {json.dumps({'type': 'status', 'message': 'üöÄ Ïó¨Ìñâ Í≥ÑÌöç ÏÉùÏÑ± ÏãúÏûë...', 'progress': 0}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(0.1)
        
        # 2. ÏßÄÏó≠ Ï∂îÏ∂ú
        yield f"data: {json.dumps({'type': 'status', 'message': 'üìç ÏßÄÏó≠ Ï†ïÎ≥¥ Ï∂îÏ∂ú Ï§ë...', 'progress': 5}, ensure_ascii=False)}\n\n"
        
        # 3. Í∞ÑÎã®Ìïú ÏßÑÌñâ Î©îÏãúÏßÄ (ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ÏóêÏÑú Ï≤òÎ¶¨)
        preferences = request.preferences or {}
        
        yield f"data: {json.dumps({'type': 'status', 'message': 'üîç Ïû•ÏÜå ÌÅ¨Î°§ÎßÅ Ï§ë...', 'progress': 20}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(3)
        
        yield f"data: {json.dumps({'type': 'status', 'message': 'ü§ñ AI Î∂ÑÏÑù Ï§ë...', 'progress': 60}, ensure_ascii=False)}\n\n"
        await asyncio.sleep(5)
        
        yield f"data: {json.dumps({'type': 'status', 'message': '‚úÖ Í≤ÄÏ¶ù Ï§ë...', 'progress': 90}, ensure_ascii=False)}\n\n"
        
        # üÜï Ïã§Ï†ú Í≥ÑÌöç ÏÉùÏÑ±ÏùÄ ÏùºÎ∞ò API Ìò∏Ï∂ú Í∂åÏû•
        yield f"data: {json.dumps({'type': 'info', 'message': 'üí° Ïã§Ï†ú Ïû•ÏÜåÎ™ÖÏùÄ ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ÏóêÏÑú ÌëúÏãúÎê©ÎãàÎã§', 'progress': 100}, ensure_ascii=False)}\n\n"
        
    except Exception as e:
        error_msg = f"Ïò§Î•ò Î∞úÏÉù: {str(e)}"
        yield f"data: {json.dumps({'type': 'error', 'message': error_msg}, ensure_ascii=False)}\n\n"


@router.post("/plan-stream")
async def create_travel_plan_stream(request: TravelPlanStreamRequest):
    """
    üåä **SSE Ïä§Ìä∏Î¶¨Î∞ç Ïó¨Ìñâ Í≥ÑÌöç ÏÉùÏÑ±**
    
    ChatGPTÏ≤òÎüº ÏßÑÌñâ ÏÉÅÌô©ÏùÑ Ïã§ÏãúÍ∞ÑÏúºÎ°ú ÌëúÏãúÌïòÎ©¥ÏÑú Ïó¨Ìñâ Í≥ÑÌöçÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.
    
    ### SSE Ïù¥Î≤§Ìä∏ ÌÉÄÏûÖ:
    - `status`: ÏßÑÌñâ ÏÉÅÌô© (Ïòà: "ÌÅ¨Î°§ÎßÅ Ï§ë...")
    - `info`: Ï†ïÎ≥¥ Î©îÏãúÏßÄ (Ïòà: "Ï≤≠ÎèÑ Ïù∏Ïãù ÏôÑÎ£å")
    - `complete`: ÏµúÏ¢Ö Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞
    - `error`: Ïò§Î•ò Î©îÏãúÏßÄ
    
    ### ÏÇ¨Ïö© ÏòàÏãú:
    ```javascript
    const eventSource = new EventSource('/api/travel/plan-stream');
    eventSource.onmessage = (event) => {
        const data = JSON.parse(event.data);
        if (data.type === 'status') {
            console.log(data.message);  // "ÌÅ¨Î°§ÎßÅ Ï§ë..."
        }
    };
    ```
    """
    return StreamingResponse(
        progress_generator(request),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # nginx Î≤ÑÌçºÎßÅ Î∞©ÏßÄ
        }
    )

