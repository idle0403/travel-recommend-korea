"""
í–¥ìƒëœ ì¥ì†Œ ë°œê²¬ ì„œë¹„ìŠ¤ - 8ë‹¨ê³„ ì•„í‚¤í…ì²˜ êµ¬í˜„ + ì§€ì—­ ì •ë°€ë„ í–¥ìƒ
"""

from typing import Dict, Any, List
from datetime import datetime, timedelta
from app.services.naver_service import NaverService
from app.services.google_maps_service import GoogleMapsService
from app.services.blog_crawler_service import BlogCrawlerService
from app.services.weather_service import WeatherService
from app.services.crawl_cache_service import CrawlCacheService
# ğŸ†• Redis ìºì‹œ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ë©”ëª¨ë¦¬ ìºì‹œ í´ë°±
try:
    from app.services.redis_cache_service import RedisCacheService
    USE_REDIS = True
except ImportError:
    USE_REDIS = False
from app.services.city_service import CityService
from app.services.district_service import DistrictService

# ğŸ†• ìƒˆë¡œìš´ ì§€ì—­ ì •ë°€ë„ ì»´í¬ë„ŒíŠ¸
from app.services.hierarchical_location_extractor import HierarchicalLocationExtractor
from app.services.context_aware_search_query_builder import ContextAwareSearchQueryBuilder
from app.services.geographic_filter import GeographicFilter
from app.services.local_context_db import LocalContextDB

class EnhancedPlaceDiscoveryService:
    def __init__(self):
        self.naver_service = NaverService()
        self.google_service = GoogleMapsService()
        self.blog_crawler = BlogCrawlerService()
        self.weather_service = WeatherService()
        
        # ğŸ†• Redis ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ë©”ëª¨ë¦¬ ìºì‹œ
        if USE_REDIS:
            self.cache_service = RedisCacheService()
            print("ğŸ¯ Redis ìºì‹œ ì„œë¹„ìŠ¤ ì‚¬ìš©")
        else:
            self.cache_service = CrawlCacheService()
            print("ğŸ“¦ ë©”ëª¨ë¦¬ ìºì‹œ ì„œë¹„ìŠ¤ ì‚¬ìš© (í´ë°±)")
        
        self.city_service = CityService()
        self.district_service = DistrictService()
        
        # ğŸ†• ìƒˆë¡œìš´ ì»´í¬ë„ŒíŠ¸ ì¶”ê°€
        self.location_extractor = HierarchicalLocationExtractor()
        self.query_builder = ContextAwareSearchQueryBuilder()
        self.geo_filter = GeographicFilter()
        self.local_context_db = LocalContextDB()  # ğŸ†• ì§€ì—­ ë§¥ë½ DB
    
    async def discover_places_with_weather(self, prompt: str, city: str, travel_dates: List[str]) -> Dict[str, Any]:
        """
        8ë‹¨ê³„ ì•„í‚¤í…ì²˜ êµ¬í˜„ + ì§€ì—­ ì •ë°€ë„ í–¥ìƒ
        
        ğŸ†• ê°œì„ ì‚¬í•­:
        - ê³„ì¸µì  ì§€ì—­ ì¶”ì¶œ (ì‹œ > êµ¬ > ë™ > POI)
        - ì»¨í…ìŠ¤íŠ¸ ì¸ì§€ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        - ì§€ë¦¬ì  í•„í„°ë§ (ì¢Œí‘œ ê¸°ë°˜)
        """
        
        print(f"\n{'='*80}")
        print(f"ğŸš€ í–¥ìƒëœ ì¥ì†Œ ë°œê²¬ ì‹œì‘")
        print(f"{'='*80}")
        
        # ğŸ†• Step 0: ê³„ì¸µì  ì§€ì—­ ì •ë³´ ì¶”ì¶œ (ë¹„ë™ê¸°)
        print(f"\nğŸ“ [Step 0] ê³„ì¸µì  ì§€ì—­ ì •ë³´ ì¶”ì¶œ")
        location_hierarchy = await self.location_extractor.extract_location_hierarchy(prompt)
        
        # ğŸ†• Step 0.1: city íŒŒë¼ë¯¸í„° ì˜¤ë²„ë¼ì´ë“œ (Autoì¸ ê²½ìš°)
        if city == "Auto" or not city:
            extracted_city = location_hierarchy.get('city')
            if extracted_city:
                print(f"   ğŸ”„ city íŒŒë¼ë¯¸í„° ì˜¤ë²„ë¼ì´ë“œ: '{city}' â†’ '{extracted_city}'")
                city = extracted_city
                # location_hierarchyëŠ” ì´ë¯¸ ì˜¬ë°”ë¥¸ ì¢Œí‘œë¥¼ ê°€ì§€ê³  ìˆìŒ (AI í•™ìŠµ ì™„ë£Œ)
        
        # ğŸ†• Step 0.5: ì§€ì—­ ë§¥ë½ ì •ë³´ ì¡°íšŒ (ì •ì  DB + ë™ì  ìƒì„±)
        print(f"\nğŸ™ï¸ [Step 0.5] ì§€ì—­ ë§¥ë½ DB ì¡°íšŒ ë˜ëŠ” ìƒì„±")
        local_context = {}
        
        # ìš°ì„ ìˆœìœ„: neighborhood > district > city
        target_location = location_hierarchy.get('neighborhood') or \
                         location_hierarchy.get('district') or \
                         location_hierarchy.get('city')
        
        if target_location:
            print(f"   ğŸ” íƒ€ê²Ÿ ì§€ì—­: {target_location}")
            
            # ë™ì  ì»¨í…ìŠ¤íŠ¸ ì¡°íšŒ/ìƒì„± (ë¹„ë™ê¸°)
            location_context = await self.local_context_db.get_or_create_context(target_location)
            
            if location_context:
                # enrich_search_with_context í˜¸ì¶œ
                local_context = self.local_context_db.enrich_search_with_context(
                    location=target_location,
                    user_request=prompt,
                    time_context=location_hierarchy.get('context', {}).get('ì‹œê°„ëŒ€', []),
                    target_context=location_hierarchy.get('context', {}).get('íƒ€ê²Ÿ', [])
                )
                
                if local_context.get('enriched'):
                    print(f"   âœ… ì§€ì—­ íŠ¹ì„± ë§¤ì¹­: {target_location}")
                    print(f"   íŠ¹ì„±: {', '.join(local_context.get('location_characteristics', [])[:3])}")
                    print(f"   ì¶”ì²œ ìŒì‹: {', '.join(local_context.get('recommended_cuisines', [])[:3])}")
                    print(f"   ê°€ê²©ëŒ€: {local_context.get('target_price_range')}")
                    print(f"   ë¶„ìœ„ê¸°: {local_context.get('atmosphere')}")
                else:
                    print(f"   â„¹ï¸ {target_location} ë§¥ë½ ì •ë³´ ì‚¬ìš© ë¶ˆê°€ (ì¼ë°˜ ê²€ìƒ‰)")
            else:
                print(f"   âš ï¸ {target_location} ë§¥ë½ ìƒì„± ì‹¤íŒ¨ (ì¼ë°˜ ê²€ìƒ‰)")
        
        # 1. í”„ë¡¬í”„íŠ¸ ë¶„ì„ ë° í‚¤ì›Œë“œ ì¶”ì¶œ
        print(f"\nğŸ”‘ [Step 1] í‚¤ì›Œë“œ ì¶”ì¶œ")
        keywords = self._extract_keywords_from_prompt(prompt)
        
        # ğŸ†• ì§€ì—­ ë§¥ë½ ê¸°ë°˜ í‚¤ì›Œë“œ í™•ì¥
        if local_context.get('enriched'):
            # ì¶”ì²œ ìŒì‹ ì¢…ë¥˜ë¥¼ í‚¤ì›Œë“œì— ì¶”ê°€
            if 'ë§›ì§‘' in keywords or 'ìŒì‹' in keywords:
                context_cuisines = local_context.get('recommended_cuisines', [])[:2]
                for cuisine in context_cuisines:
                    if cuisine not in keywords:
                        keywords.append(cuisine)
                        print(f"   ğŸ†• ë§¥ë½ ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ê°€: {cuisine}")
        
        print(f"   ìµœì¢… í‚¤ì›Œë“œ: {keywords}")
        
        # ğŸ†• Step 1.5: ì»¨í…ìŠ¤íŠ¸ ì¸ì§€ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        print(f"\nğŸ” [Step 1.5] ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±")
        search_queries = self.query_builder.build_search_queries(location_hierarchy, keywords)
        primary_queries = self.query_builder.get_primary_queries(search_queries, top_n=5)
        
        # ğŸ†• Step 1.8: ì—¬í–‰ ì¼ìˆ˜ì— ë”°ë¥¸ í•„ìš” ì¥ì†Œ ìˆ˜ ê³„ì‚°
        days_count = len(travel_dates) if travel_dates else 1
        if days_count == 1:
            # ë‹¹ì¼ì¹˜ê¸°: ì‹œê°„ë‹¹ 1-2ê°œ Ã— 8ì‹œê°„ = 8-16ê°œ
            required_places = 16
            places_per_keyword = 10
        elif days_count == 2:
            # 1ë°•2ì¼: í•˜ë£¨ 8ê°œ Ã— 2ì¼ = 16ê°œ + ì—¬ìœ ë¶„ = 30ê°œ
            required_places = 30
            places_per_keyword = 15
        elif days_count >= 3:
            # 2ë°•3ì¼ ì´ìƒ: í•˜ë£¨ 8ê°œ Ã— ì¼ìˆ˜ + 50% ì—¬ìœ 
            required_places = days_count * 8 * 1.5
            places_per_keyword = 20
        else:
            required_places = 16
            places_per_keyword = 10
        
        print(f"\nğŸ“Š ì—¬í–‰ ì¼ìˆ˜: {days_count}ì¼, í•„ìš” ì¥ì†Œ: {required_places}ê°œ (í‚¤ì›Œë“œë‹¹ {places_per_keyword}ê°œ)")
        
        # 2. ë‚ ì”¨ ì •ë³´ ì¡°íšŒ (ì§€ì •ëœ ì¼ì)
        print(f"\nğŸŒ¦ï¸ [Step 2] ë‚ ì”¨ ì •ë³´ ì¡°íšŒ")
        weather_data = await self._get_weather_for_dates(city, travel_dates)
        
        # 3. ìºì‹œ í™•ì¸ í›„ í¬ë¡¤ë§ (ì¤‘ë³µ ë°©ì§€) - ğŸ†• ì •ë°€ ê²€ìƒ‰ ì¿¼ë¦¬ ì‚¬ìš©
        print(f"\nğŸ’¾ [Step 3] ì¥ì†Œ ë°ì´í„° ìˆ˜ì§‘ (ìºì‹œ + í¬ë¡¤ë§)")
        all_places = []
        
        # ê¸°ì¡´ í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ (ğŸ†• ì¥ê¸° ì—¬í–‰ì€ ë” ë§ì´ í¬ë¡¤ë§)
        for keyword in keywords:
            search_key = self.cache_service.generate_search_key(city, keyword)
            
            cached_places = self.cache_service.get_cached_data(search_key)
            if cached_places:
                print(f"   âœ… ìºì‹œ ì‚¬ìš©: {search_key} ({len(cached_places)}ê°œ)")
                all_places.extend(cached_places)
            else:
                print(f"   ğŸ” ìƒˆ í¬ë¡¤ë§: {search_key} (ìš”ì²­: {places_per_keyword}ê°œ)")
                new_places = await self._crawl_places_by_keyword(city, keyword, display=places_per_keyword)
                if new_places:
                    self.cache_service.save_crawled_data(search_key, new_places)
                    all_places.extend(new_places)
        
        # ğŸ†• ì •ë°€ ê²€ìƒ‰ ì¿¼ë¦¬ ê¸°ë°˜ ì¶”ê°€ ê²€ìƒ‰ (ğŸ†• ì¥ê¸° ì—¬í–‰ì€ ë” ë§ì´)
        query_count = 5 if days_count >= 2 else 3  # 1ë°•2ì¼ ì´ìƒì´ë©´ ì¿¼ë¦¬ ë” ë§ì´
        for query_info in search_queries[:query_count]:
            query = query_info['query']
            search_key = self.cache_service.generate_search_key("", query)
            
            cached_places = self.cache_service.get_cached_data(search_key)
            if cached_places:
                print(f"   âœ… ìºì‹œ ì‚¬ìš© (ì •ë°€): {query} ({len(cached_places)}ê°œ)")
                all_places.extend(cached_places)
            else:
                print(f"   ğŸ” ìƒˆ í¬ë¡¤ë§ (ì •ë°€): {query} (ìš”ì²­: {places_per_keyword}ê°œ)")
                new_places = await self._crawl_places_by_precise_query(query, display=places_per_keyword)
                if new_places:
                    self.cache_service.save_crawled_data(search_key, new_places)
                    all_places.extend(new_places)
        
        print(f"   ğŸ“Š ì´ ìˆ˜ì§‘ëœ ì¥ì†Œ: {len(all_places)}ê°œ")
        
        # ğŸ†• Step 3.5: ì§€ë¦¬ì  í•„í„°ë§ (ì¢Œí‘œ ê¸°ë°˜)
        print(f"\nğŸ—ºï¸ [Step 3.5] ì§€ë¦¬ì  í•„í„°ë§")
        geo_filtered_places = self.geo_filter.filter_by_distance(
            places=all_places,
            center_lat=location_hierarchy['lat'],
            center_lng=location_hierarchy['lng'],
            radius_km=location_hierarchy['search_radius_km'],
            location_text=location_hierarchy['location_text']
        )
        
        # ğŸ†• ì£¼ì†Œ ê¸°ë°˜ ë³´ì¡° í•„í„°ë§
        if location_hierarchy.get('district'):
            geo_filtered_places = self.geo_filter.filter_by_address(
                places=geo_filtered_places,
                required_district=location_hierarchy.get('district'),
                required_neighborhood=location_hierarchy.get('neighborhood')
            )
        
        # ğŸ†• ê±°ë¦¬ + í‰ì  ê¸°ë°˜ ì¬ì •ë ¬
        geo_filtered_places = self.geo_filter.rerank_by_distance_and_rating(
            places=geo_filtered_places,
            distance_weight=0.4,
            rating_weight=0.6
        )
        
        print(f"   âœ… ì§€ë¦¬ì  í•„í„°ë§ ì™„ë£Œ: {len(geo_filtered_places)}ê°œ")
        
        # ğŸ†• ì¥ì†Œê°€ 0ê°œë©´ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜ (ë””í´íŠ¸ ê°’ ëŒ€ì‹ )
        if len(geo_filtered_places) == 0:
            requested_region = location_hierarchy.get('city', 'N/A')
            if location_hierarchy.get('district'):
                requested_region += f" {location_hierarchy.get('district')}"
            
            error_msg = f"í•´ë‹¹ ì§€ì—­('{requested_region}')ì—ì„œ ì í•©í•œ ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
            error_msg += f"ì´ {len(all_places)}ê°œ ì¥ì†Œë¥¼ ìˆ˜ì§‘í–ˆìœ¼ë‚˜ ì§€ë¦¬ì  í•„í„°ë§ í›„ 0ê°œê°€ ë‚¨ì•˜ìŠµë‹ˆë‹¤. "
            
            if location_hierarchy.get('district'):
                error_msg += f"'{location_hierarchy.get('city')}' ì „ì²´ë¡œ ê²€ìƒ‰ì„ ë„“í˜€ë³´ì‹œê±°ë‚˜, "
            
            error_msg += "ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
            
            print(f"\nâŒ ì—ëŸ¬: {error_msg}")
            raise ValueError(error_msg)
        
        # 4. AI ë¶„ì„ ë° ì¶”ì²œ (ë‚ ì”¨ ê³ ë ¤)
        print(f"\nğŸ¤– [Step 4] AI ë¶„ì„ ë° ì¶”ì²œ")
        ai_recommendations = await self._ai_analyze_with_weather(geo_filtered_places, weather_data, prompt)
        
        # 5. ì¥ì†Œ ê²€ì¦ (í• ë£¨ì‹œë„¤ì´ì…˜ ì œê±°)
        print(f"\nâœ… [Step 5] ì¥ì†Œ ê²€ì¦")
        verified_places = await self._verify_recommended_places(ai_recommendations)
        
        # 6. ìµœì  ë™ì„  ê³„ì‚°
        print(f"\nğŸ›£ï¸ [Step 6] ìµœì  ë™ì„  ê³„ì‚°")
        optimized_route = await self._calculate_optimal_route(verified_places, city)
        
        # 7. ì¥ê¸° ì—¬í–‰ì‹œ êµ¬ì—­ë³„ ì„¸ë¶„í™”
        if len(travel_dates) > 1:
            print(f"\nğŸ“… [Step 7] êµ¬ì—­ë³„ ì„¸ë¶„í™” (ë‹¤ì¼ ì—¬í–‰)")
            district_recommendations = await self._get_district_recommendations(city, len(travel_dates))
            optimized_route = self._merge_with_districts(optimized_route, district_recommendations)
        
        print(f"\n{'='*80}")
        print(f"âœ¨ ì¥ì†Œ ë°œê²¬ ì™„ë£Œ!")
        print(f"{'='*80}\n")
        
        return {
            "extracted_keywords": keywords,
            "location_hierarchy": location_hierarchy,  # ğŸ†• ì¶”ê°€
            "local_context": local_context,  # ğŸ†• ì§€ì—­ ë§¥ë½ ì •ë³´
            "search_queries": search_queries,  # ğŸ†• ì¶”ê°€
            "weather_forecast": weather_data,
            "total_places_found": len(all_places),
            "geo_filtered_count": len(geo_filtered_places),  # ğŸ†• ì¶”ê°€
            "ai_recommendations": ai_recommendations,
            "verified_places": verified_places,
            "optimized_route": optimized_route,
            "travel_dates": travel_dates,
            "cache_usage": self._get_cache_stats(keywords, city)
        }
    
    async def _get_weather_for_dates(self, city: str, dates: List[str]) -> Dict[str, Any]:
        """ì§€ì •ëœ ì¼ìë“¤ì˜ ë‚ ì”¨ ì •ë³´"""
        weather_code = self.city_service.get_weather_code(city)
        weather_data = {}
        
        for date in dates:
            # í˜„ì¬ëŠ” í˜„ì¬ ë‚ ì”¨ë§Œ ì§€ì›, ì‹¤ì œë¡œëŠ” ë‚ ì§œë³„ ì˜ˆë³´ í•„ìš”
            daily_weather = await self.weather_service.get_current_weather(weather_code)
            weather_data[date] = daily_weather
        
        return weather_data
    
    async def _crawl_places_by_keyword(self, city: str, keyword: str, display: int = 15) -> List[Dict[str, Any]]:
        """í‚¤ì›Œë“œë³„ ì¥ì†Œ í¬ë¡¤ë§"""
        search_query = f"{city} {keyword}"
        
        # ë„¤ì´ë²„ ê²€ìƒ‰ (ğŸ†• display íŒŒë¼ë¯¸í„° ì‚¬ìš©)
        naver_places = await self.naver_service.search_places(search_query, display=display)
        
        enhanced_places = []
        for place in naver_places:
            place_name = place.get('name', '')
            
            # êµ¬ê¸€ ì •ë³´ ì¶”ê°€
            google_details = await self.google_service.get_place_details(
                place_name, place.get('address', '')
            )
            
            # âœ… ê° ì¥ì†Œë³„ë¡œ ê°œë³„ ë¸”ë¡œê·¸ ê²€ìƒ‰
            blog_reviews = await self.naver_service.search_blogs(f"{place_name} í›„ê¸°", display=5)
            print(f"ğŸ“ {place_name}: ë¸”ë¡œê·¸ í›„ê¸° {len(blog_reviews)}ê°œ ìˆ˜ì§‘")
            
            # ë¸”ë¡œê·¸ í¬ë¡¤ë§
            blog_contents = []
            if blog_reviews:
                blog_urls = [blog.get('link') for blog in blog_reviews[:3]]
                blog_contents = await self.blog_crawler.get_multiple_blog_contents(blog_urls)
            
            enhanced_place = {
                **place,
                'google_info': google_details,
                'blog_reviews': blog_reviews,  # âœ… ì¥ì†Œë³„ ê°œë³„ í›„ê¸°
                'blog_contents': blog_contents,
                'verified': bool(place.get('name') and google_details.get('name')),
                'crawl_timestamp': datetime.now().isoformat()
            }
            enhanced_places.append(enhanced_place)
        
        return enhanced_places
    
    async def _ai_analyze_with_weather(self, places: List[Dict], weather_data: Dict, prompt: str) -> List[Dict]:
        """AIê°€ ë‚ ì”¨ë¥¼ ê³ ë ¤í•˜ì—¬ ì¥ì†Œ ë¶„ì„ ë° ì¶”ì²œ"""
        # ë‚ ì”¨ ê¸°ë°˜ í•„í„°ë§
        weather_filtered = []
        
        for date, weather in weather_data.items():
            if weather.get('is_rainy'):
                # ë¹„ì˜¤ëŠ” ë‚ : ì‹¤ë‚´ ì¥ì†Œ ìš°ì„ 
                indoor_places = [p for p in places if self._is_indoor_place(p)]
                weather_filtered.extend(indoor_places)
            else:
                # ë§‘ì€ ë‚ : ëª¨ë“  ì¥ì†Œ ê°€ëŠ¥
                weather_filtered.extend(places)
        
        # ì¤‘ë³µ ì œê±° ë° í‰ì ìˆœ ì •ë ¬
        unique_places = self._deduplicate_places(weather_filtered)
        return sorted(unique_places, key=lambda x: x.get('google_info', {}).get('rating', 0), reverse=True)[:20]
    
    async def _verify_recommended_places(self, recommendations: List[Dict]) -> List[Dict]:
        """ì¶”ì²œëœ ì¥ì†Œë“¤ì˜ ì‹¤ì œ ì¡´ì¬ ì—¬ë¶€ ê²€ì¦"""
        verified = []
        for place in recommendations:
            # ë„¤ì´ë²„ + êµ¬ê¸€ ë‘˜ ë‹¤ í™•ì¸ë˜ë©´ ê²€ì¦ë¨
            has_naver = bool(place.get('name'))
            has_google = bool(place.get('google_info', {}).get('name'))
            
            if has_naver and has_google:
                place['verification_status'] = 'verified'
                verified.append(place)
            elif has_naver or has_google:
                place['verification_status'] = 'partial'
                verified.append(place)
        
        return verified
    
    async def _calculate_optimal_route(self, places: List[Dict], city: str) -> Dict[str, Any]:
        """
        ìµœì  ë™ì„  ê³„ì‚°
        
        Returns:
            í”„ë¡ íŠ¸ì—”ë“œì™€ í˜¸í™˜ë˜ëŠ” ê²½ë¡œ ì •ë³´ (polyline, locations, bounds í¬í•¨)
        """
        if len(places) < 2:
            return {
                "places": places,
                "locations": places,  # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±
                "total_distance": "0km",
                "total_time": "0ë¶„",
                "polyline": ""
            }
        
        # êµ¬ì—­ë³„ í´ëŸ¬ìŠ¤í„°ë§
        clustered = self.district_service.create_district_based_itinerary(
            city, "custom", len(places) * 2, None
        )
        
        # Google Mapsë¡œ ê²½ë¡œ ìµœì í™”
        locations = [
            {
                "lat": p.get('lat', 37.5665),
                "lng": p.get('lng', 126.9780),
                "name": p.get('name', 'Unknown')
            }
            for p in places
        ]
        route_info = await self.google_service.get_optimized_route(locations)
        
        # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ í‰íƒ„í™”
        # route_infoëŠ” ì´ë¯¸ polyline, bounds, locationsë¥¼ í¬í•¨í•˜ê³  ìˆìŒ
        result = {
            "places": places,
            "locations": locations,  # í”„ë¡ íŠ¸ì—”ë“œê°€ ê¸°ëŒ€í•˜ëŠ” í•„ë“œ
            "clustered_districts": clustered
        }
        
        # route_infoì˜ í•„ë“œë“¤ì„ ìµœìƒìœ„ë¡œ ë³µì‚¬
        if route_info:
            result.update({
                "polyline": route_info.get("polyline", ""),
                "bounds": route_info.get("bounds", {}),
                "total_distance": route_info.get("total_distance", "0km"),
                "total_duration": route_info.get("total_duration", "0ë¶„"),
                "route_segments": route_info.get("route_segments", []),
                "optimized_order": route_info.get("optimized_order", []),
                "waypoint_order": route_info.get("waypoint_order", [])
            })
        
        return result
    
    async def _get_district_recommendations(self, city: str, days_count: int) -> Dict[str, List]:
        """ì¥ê¸° ì—¬í–‰ì‹œ êµ¬ì—­ë³„ ì„¸ë¶„í™” ì¶”ì²œ"""
        districts = self.district_service.get_districts_by_city(city)
        recommendations = {}
        
        for district_name, district_info in districts.items():
            # ê° êµ¬ì—­ë³„ë¡œ ê´€ê´‘ì§€/ë§›ì§‘/í˜¸í…” í¬ë¡¤ë§
            attractions = await self._crawl_places_by_keyword(city, f"{district_name} ê´€ê´‘ì§€")
            restaurants = await self._crawl_places_by_keyword(city, f"{district_name} ë§›ì§‘")
            
            if days_count > 2:  # 2ë°• ì´ìƒì‹œ í˜¸í…” ì •ë³´ë„ ì¶”ê°€
                hotels = await self._crawl_places_by_keyword(city, f"{district_name} í˜¸í…”")
                recommendations[district_name] = {
                    "attractions": attractions[:5],
                    "restaurants": restaurants[:5], 
                    "hotels": hotels[:3]
                }
            else:
                recommendations[district_name] = {
                    "attractions": attractions[:3],
                    "restaurants": restaurants[:3]
                }
        
        return recommendations
    
    def _merge_with_districts(self, route: Dict, districts: Dict) -> Dict:
        """ê¸°ë³¸ ê²½ë¡œì™€ êµ¬ì—­ë³„ ì¶”ì²œ ë³‘í•©"""
        route['district_recommendations'] = districts
        return route
    
    def _is_indoor_place(self, place: Dict) -> bool:
        """ì‹¤ë‚´ ì¥ì†Œ ì—¬ë¶€ íŒë‹¨"""
        indoor_keywords = ['ì¹´í˜', 'ë°•ë¬¼ê´€', 'ë¯¸ìˆ ê´€', 'ì‡¼í•‘ëª°', 'ì˜í™”ê´€', 'ì‹¤ë‚´', 'ì§€í•˜']
        place_info = f"{place.get('name', '')} {place.get('category', '')}"
        return any(keyword in place_info for keyword in indoor_keywords)
    
    def _deduplicate_places(self, places: List[Dict]) -> List[Dict]:
        """ì¤‘ë³µ ì¥ì†Œ ì œê±°"""
        seen = set()
        unique = []
        for place in places:
            key = f"{place.get('name', '')}_{place.get('address', '')}"
            if key not in seen:
                seen.add(key)
                unique.append(place)
        return unique
    
    def _extract_keywords_from_prompt(self, prompt: str) -> List[str]:
        """í”„ë¡¬í”„íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        
        # ê¸°ë³¸ í‚¤ì›Œë“œ íŒ¨í„´
        if 'ë§›ì§‘' in prompt or 'ìŒì‹' in prompt:
            keywords.append('ë§›ì§‘')
        if 'ê´€ê´‘' in prompt or 'ëª…ì†Œ' in prompt:
            keywords.append('ê´€ê´‘ì§€')
        if 'ì¹´í˜' in prompt:
            keywords.append('ì¹´í˜')
        if 'ì‡¼í•‘' in prompt:
            keywords.append('ì‡¼í•‘')
        if 'í˜¸í…”' in prompt or 'ìˆ™ë°•' in prompt:
            keywords.append('í˜¸í…”')
        
        return keywords if keywords else ['ê´€ê´‘ì§€', 'ë§›ì§‘']
    
    def _get_cache_stats(self, keywords: List[str], city: str) -> Dict:
        """ìºì‹œ ì‚¬ìš© í†µê³„"""
        stats = {"cached": 0, "new_crawl": 0}
        for keyword in keywords:
            search_key = self.cache_service.generate_search_key(city, keyword)
            cached_data = self.cache_service.get_cached_data(search_key)
            if cached_data:
                stats["cached"] += 1
            else:
                stats["new_crawl"] += 1
        return stats
    
    async def _crawl_places_by_precise_query(self, query: str, display: int = 15) -> List[Dict[str, Any]]:
        """
        ğŸ†• ì •ë°€ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì¥ì†Œ í¬ë¡¤ë§
        
        Args:
            query: ì •ë°€ ê²€ìƒ‰ ì¿¼ë¦¬ (ì˜ˆ: "ì„œìš¸ ê°•ì„œêµ¬ ë§ˆê³¡ë™ ë§›ì§‘")
            display: ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ (ğŸ†• ì¥ê¸° ì—¬í–‰ì€ ë” ë§ì´)
        
        Returns:
            ì¥ì†Œ ë¦¬ìŠ¤íŠ¸
        """
        # ë„¤ì´ë²„ ê²€ìƒ‰
        naver_places = await self.naver_service.search_places(query, display=display)
        
        enhanced_places = []
        for place in naver_places:
            place_name = place.get('name', '')
            
            # êµ¬ê¸€ ì •ë³´ ì¶”ê°€
            google_details = await self.google_service.get_place_details(
                place_name, place.get('address', '')
            )
            
            # ë¸”ë¡œê·¸ ê²€ìƒ‰ (ê°œë³„)
            blog_reviews = await self.naver_service.search_blogs(f"{place_name} í›„ê¸°", display=3)
            
            # ë¸”ë¡œê·¸ í¬ë¡¤ë§
            blog_contents = []
            if blog_reviews:
                blog_urls = [blog.get('link') for blog in blog_reviews[:2]]
                blog_contents = await self.blog_crawler.get_multiple_blog_contents(blog_urls)
            
            enhanced_place = {
                **place,
                'google_info': google_details,
                'blog_reviews': blog_reviews,
                'blog_contents': blog_contents,
                'verified': bool(place.get('name') and google_details.get('name')),
                'crawl_timestamp': datetime.now().isoformat()
            }
            enhanced_places.append(enhanced_place)
        
        return enhanced_places